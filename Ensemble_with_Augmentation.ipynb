{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UBvSdsa3c_o3",
        "outputId": "b384ea57-a92b-4720-c5b7-b2f592865ef0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (2.12.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (67.6.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.53.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.8)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (0.0.4)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (6.3.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Training model 1\n",
            "Epoch 1/100\n",
            "92/92 [==============================] - 9s 91ms/step - loss: 1.0654 - accuracy: 0.5188 - val_loss: 0.7375 - val_accuracy: 0.7152\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 7s 77ms/step - loss: 0.6707 - accuracy: 0.7101 - val_loss: 0.5289 - val_accuracy: 0.7988\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 8s 88ms/step - loss: 0.4916 - accuracy: 0.8039 - val_loss: 0.4396 - val_accuracy: 0.8287\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 6s 63ms/step - loss: 0.3956 - accuracy: 0.8485 - val_loss: 0.3794 - val_accuracy: 0.8647\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 0.3162 - accuracy: 0.8822 - val_loss: 0.3400 - val_accuracy: 0.8729\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.2906 - accuracy: 0.8900 - val_loss: 0.4137 - val_accuracy: 0.8362\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 7s 80ms/step - loss: 0.2502 - accuracy: 0.9075 - val_loss: 0.3184 - val_accuracy: 0.8838\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 0.2191 - accuracy: 0.9165 - val_loss: 0.3121 - val_accuracy: 0.8722\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 7s 75ms/step - loss: 0.1895 - accuracy: 0.9286 - val_loss: 0.2901 - val_accuracy: 0.8878\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 0.1801 - accuracy: 0.9289 - val_loss: 0.3091 - val_accuracy: 0.8919\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 7s 73ms/step - loss: 0.1575 - accuracy: 0.9424 - val_loss: 0.2888 - val_accuracy: 0.8885\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 7s 73ms/step - loss: 0.1519 - accuracy: 0.9395 - val_loss: 0.3130 - val_accuracy: 0.8953\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.1370 - accuracy: 0.9476 - val_loss: 0.2960 - val_accuracy: 0.8926\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 8s 85ms/step - loss: 0.1169 - accuracy: 0.9578 - val_loss: 0.3081 - val_accuracy: 0.8953\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 6s 64ms/step - loss: 0.1087 - accuracy: 0.9612 - val_loss: 0.2934 - val_accuracy: 0.8994\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 8s 88ms/step - loss: 0.1046 - accuracy: 0.9636 - val_loss: 0.2768 - val_accuracy: 0.9001\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 6s 66ms/step - loss: 0.1156 - accuracy: 0.9536 - val_loss: 0.3185 - val_accuracy: 0.8831\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 8s 84ms/step - loss: 0.0951 - accuracy: 0.9648 - val_loss: 0.2870 - val_accuracy: 0.9075\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 6s 64ms/step - loss: 0.0872 - accuracy: 0.9665 - val_loss: 0.2940 - val_accuracy: 0.9035\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 8s 85ms/step - loss: 0.0714 - accuracy: 0.9743 - val_loss: 0.2968 - val_accuracy: 0.9069\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.0726 - accuracy: 0.9747 - val_loss: 0.3045 - val_accuracy: 0.9035\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 7s 81ms/step - loss: 0.0754 - accuracy: 0.9733 - val_loss: 0.2943 - val_accuracy: 0.9089\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 6s 69ms/step - loss: 0.0601 - accuracy: 0.9787 - val_loss: 0.3139 - val_accuracy: 0.9048\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 7s 73ms/step - loss: 0.0567 - accuracy: 0.9811 - val_loss: 0.3036 - val_accuracy: 0.9069\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 7s 76ms/step - loss: 0.0505 - accuracy: 0.9842 - val_loss: 0.3678 - val_accuracy: 0.9048\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 6s 66ms/step - loss: 0.0503 - accuracy: 0.9804 - val_loss: 0.3305 - val_accuracy: 0.9075\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 8s 85ms/step - loss: 0.0451 - accuracy: 0.9847 - val_loss: 0.3355 - val_accuracy: 0.9109\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 0.0412 - accuracy: 0.9850 - val_loss: 0.3774 - val_accuracy: 0.8899\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 8s 84ms/step - loss: 0.0438 - accuracy: 0.9857 - val_loss: 0.3821 - val_accuracy: 0.9035\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 6s 63ms/step - loss: 0.0364 - accuracy: 0.9883 - val_loss: 0.3655 - val_accuracy: 0.9055\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 8s 88ms/step - loss: 0.0461 - accuracy: 0.9820 - val_loss: 0.3578 - val_accuracy: 0.8973\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.0462 - accuracy: 0.9847 - val_loss: 0.4131 - val_accuracy: 0.9001\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 8s 88ms/step - loss: 0.0338 - accuracy: 0.9883 - val_loss: 0.4682 - val_accuracy: 0.8960\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 6s 66ms/step - loss: 0.0404 - accuracy: 0.9847 - val_loss: 0.4356 - val_accuracy: 0.9014\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 8s 84ms/step - loss: 0.0275 - accuracy: 0.9906 - val_loss: 0.4040 - val_accuracy: 0.9055\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 6s 63ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 0.4282 - val_accuracy: 0.9055\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 7s 76ms/step - loss: 0.0232 - accuracy: 0.9930 - val_loss: 0.3923 - val_accuracy: 0.9035\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 0.0196 - accuracy: 0.9951 - val_loss: 0.4096 - val_accuracy: 0.9075\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.0168 - accuracy: 0.9957 - val_loss: 0.4282 - val_accuracy: 0.9089\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 7s 79ms/step - loss: 0.0144 - accuracy: 0.9964 - val_loss: 0.4305 - val_accuracy: 0.9055\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 6s 66ms/step - loss: 0.0132 - accuracy: 0.9974 - val_loss: 0.4609 - val_accuracy: 0.9069\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 8s 87ms/step - loss: 0.0126 - accuracy: 0.9978 - val_loss: 0.4623 - val_accuracy: 0.9103\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 6s 63ms/step - loss: 0.0150 - accuracy: 0.9963 - val_loss: 0.4947 - val_accuracy: 0.8987\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 8s 87ms/step - loss: 0.0239 - accuracy: 0.9912 - val_loss: 0.4973 - val_accuracy: 0.8980\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 6s 65ms/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.5231 - val_accuracy: 0.8960\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 8s 87ms/step - loss: 0.0241 - accuracy: 0.9918 - val_loss: 0.5145 - val_accuracy: 0.9041\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 6s 65ms/step - loss: 0.0072 - accuracy: 0.9997 - val_loss: 0.4915 - val_accuracy: 0.9069\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 7s 78ms/step - loss: 0.0063 - accuracy: 0.9993 - val_loss: 0.4883 - val_accuracy: 0.9048\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 6s 66ms/step - loss: 0.0080 - accuracy: 0.9981 - val_loss: 0.5401 - val_accuracy: 0.9075\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 0.0069 - accuracy: 0.9991 - val_loss: 0.5388 - val_accuracy: 0.9028\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 7s 80ms/step - loss: 0.0042 - accuracy: 0.9998 - val_loss: 0.5252 - val_accuracy: 0.9041\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5421 - val_accuracy: 0.9041\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 8s 82ms/step - loss: 0.0048 - accuracy: 0.9997 - val_loss: 0.5390 - val_accuracy: 0.9021\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 6s 63ms/step - loss: 0.0241 - accuracy: 0.9906 - val_loss: 0.6226 - val_accuracy: 0.8885\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 8s 87ms/step - loss: 0.1818 - accuracy: 0.9434 - val_loss: 0.5312 - val_accuracy: 0.8810\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 6s 66ms/step - loss: 0.0665 - accuracy: 0.9762 - val_loss: 0.5399 - val_accuracy: 0.8885\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 8s 84ms/step - loss: 0.0193 - accuracy: 0.9952 - val_loss: 0.5272 - val_accuracy: 0.8987\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 6s 61ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.9075\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 7s 76ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.5134 - val_accuracy: 0.9096\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5311 - val_accuracy: 0.9062\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 6s 64ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5546 - val_accuracy: 0.9062\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 7s 79ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5617 - val_accuracy: 0.9048\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 6s 62ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5466 - val_accuracy: 0.9048\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 8s 84ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5401 - val_accuracy: 0.9089\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 6s 61ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5550 - val_accuracy: 0.9048\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 8s 84ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5594 - val_accuracy: 0.9069\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 6s 62ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5701 - val_accuracy: 0.9075\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 7s 75ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5833 - val_accuracy: 0.9096\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5806 - val_accuracy: 0.9062\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5854 - val_accuracy: 0.9069\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 7s 79ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5874 - val_accuracy: 0.9075\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 6s 63ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6129 - val_accuracy: 0.9062\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 8s 84ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6052 - val_accuracy: 0.9048\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 6s 61ms/step - loss: 9.9739e-04 - accuracy: 1.0000 - val_loss: 0.6136 - val_accuracy: 0.9062\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 9.0294e-04 - accuracy: 1.0000 - val_loss: 0.6199 - val_accuracy: 0.9055\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 6s 62ms/step - loss: 8.5520e-04 - accuracy: 1.0000 - val_loss: 0.6211 - val_accuracy: 0.9048\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 7s 77ms/step - loss: 7.8152e-04 - accuracy: 1.0000 - val_loss: 0.6374 - val_accuracy: 0.9048\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 6s 69ms/step - loss: 7.4421e-04 - accuracy: 1.0000 - val_loss: 0.6342 - val_accuracy: 0.9062\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 7.0698e-04 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.9062\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 7s 78ms/step - loss: 6.6927e-04 - accuracy: 1.0000 - val_loss: 0.6492 - val_accuracy: 0.9062\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 6s 63ms/step - loss: 6.3866e-04 - accuracy: 1.0000 - val_loss: 0.6566 - val_accuracy: 0.9062\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 8s 84ms/step - loss: 6.3584e-04 - accuracy: 1.0000 - val_loss: 0.6537 - val_accuracy: 0.9048\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 6s 63ms/step - loss: 5.9181e-04 - accuracy: 1.0000 - val_loss: 0.6562 - val_accuracy: 0.9062\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 5.2896e-04 - accuracy: 1.0000 - val_loss: 0.6673 - val_accuracy: 0.9048\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 6s 61ms/step - loss: 4.8646e-04 - accuracy: 1.0000 - val_loss: 0.6708 - val_accuracy: 0.9048\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 7s 81ms/step - loss: 4.7976e-04 - accuracy: 1.0000 - val_loss: 0.6670 - val_accuracy: 0.9055\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 6s 65ms/step - loss: 4.5676e-04 - accuracy: 1.0000 - val_loss: 0.6848 - val_accuracy: 0.9055\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 3.9369e-04 - accuracy: 1.0000 - val_loss: 0.6892 - val_accuracy: 0.9075\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 7s 79ms/step - loss: 3.8981e-04 - accuracy: 1.0000 - val_loss: 0.6894 - val_accuracy: 0.9048\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 6s 66ms/step - loss: 3.4251e-04 - accuracy: 1.0000 - val_loss: 0.6880 - val_accuracy: 0.9075\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 8s 85ms/step - loss: 3.2364e-04 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.9041\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 6s 63ms/step - loss: 3.2857e-04 - accuracy: 1.0000 - val_loss: 0.7150 - val_accuracy: 0.9035\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 8s 88ms/step - loss: 3.0103e-04 - accuracy: 1.0000 - val_loss: 0.7218 - val_accuracy: 0.9014\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 2.9250e-04 - accuracy: 1.0000 - val_loss: 0.7236 - val_accuracy: 0.9041\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 8s 85ms/step - loss: 3.0247e-04 - accuracy: 1.0000 - val_loss: 0.7715 - val_accuracy: 0.9055\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 6s 63ms/step - loss: 0.1412 - accuracy: 0.9704 - val_loss: 1.0149 - val_accuracy: 0.8328\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 8s 82ms/step - loss: 0.1671 - accuracy: 0.9514 - val_loss: 0.6257 - val_accuracy: 0.8939\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 0.6623 - val_accuracy: 0.8831\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 7s 75ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.5572 - val_accuracy: 0.9082\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 7s 70ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6048 - val_accuracy: 0.9041\n",
            "93/93 [==============================] - 1s 10ms/step - loss: 0.7943 - accuracy: 0.8422\n",
            "Test accuracy of model 1: 0.8422\n",
            "Training model 2\n",
            "Epoch 1/100\n",
            "92/92 [==============================] - 10s 100ms/step - loss: 1.0726 - accuracy: 0.5164 - val_loss: 0.7990 - val_accuracy: 0.6247\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 0.6905 - accuracy: 0.7019 - val_loss: 0.5941 - val_accuracy: 0.7600\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 0.5493 - accuracy: 0.7689 - val_loss: 0.4983 - val_accuracy: 0.7981\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 6s 63ms/step - loss: 0.4416 - accuracy: 0.8298 - val_loss: 0.4327 - val_accuracy: 0.8273\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 7s 77ms/step - loss: 0.3852 - accuracy: 0.8519 - val_loss: 0.3805 - val_accuracy: 0.8586\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 0.3293 - accuracy: 0.8749 - val_loss: 0.3799 - val_accuracy: 0.8436\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 6s 69ms/step - loss: 0.3025 - accuracy: 0.8784 - val_loss: 0.3486 - val_accuracy: 0.8715\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 8s 83ms/step - loss: 0.2482 - accuracy: 0.9087 - val_loss: 0.3498 - val_accuracy: 0.8613\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 0.2234 - accuracy: 0.9180 - val_loss: 0.2953 - val_accuracy: 0.8912\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 8s 88ms/step - loss: 0.2256 - accuracy: 0.9124 - val_loss: 0.3906 - val_accuracy: 0.8484\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.2099 - accuracy: 0.9213 - val_loss: 0.2736 - val_accuracy: 0.9028\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.1643 - accuracy: 0.9412 - val_loss: 0.3002 - val_accuracy: 0.8919\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 6s 64ms/step - loss: 0.1530 - accuracy: 0.9429 - val_loss: 0.2711 - val_accuracy: 0.9055\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 8s 90ms/step - loss: 0.1391 - accuracy: 0.9507 - val_loss: 0.2705 - val_accuracy: 0.9007\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 6s 64ms/step - loss: 0.1288 - accuracy: 0.9532 - val_loss: 0.2960 - val_accuracy: 0.8892\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 0.1333 - accuracy: 0.9488 - val_loss: 0.3122 - val_accuracy: 0.8912\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 0.1103 - accuracy: 0.9616 - val_loss: 0.2901 - val_accuracy: 0.8987\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 0.1061 - accuracy: 0.9614 - val_loss: 0.3246 - val_accuracy: 0.8878\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 6s 65ms/step - loss: 0.0969 - accuracy: 0.9655 - val_loss: 0.2940 - val_accuracy: 0.9048\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 7s 79ms/step - loss: 0.0914 - accuracy: 0.9665 - val_loss: 0.3113 - val_accuracy: 0.9014\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 7s 74ms/step - loss: 0.0871 - accuracy: 0.9684 - val_loss: 0.3100 - val_accuracy: 0.8973\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 0.0806 - accuracy: 0.9728 - val_loss: 0.3186 - val_accuracy: 0.8858\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 8s 82ms/step - loss: 0.0814 - accuracy: 0.9706 - val_loss: 0.4113 - val_accuracy: 0.8783\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 0.0758 - accuracy: 0.9747 - val_loss: 0.3204 - val_accuracy: 0.8987\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 8s 82ms/step - loss: 0.0655 - accuracy: 0.9760 - val_loss: 0.3292 - val_accuracy: 0.8994\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 6s 64ms/step - loss: 0.0593 - accuracy: 0.9793 - val_loss: 0.3373 - val_accuracy: 0.8926\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.0744 - accuracy: 0.9708 - val_loss: 0.3916 - val_accuracy: 0.8933\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.0628 - accuracy: 0.9759 - val_loss: 0.3834 - val_accuracy: 0.8858\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.0529 - accuracy: 0.9820 - val_loss: 0.3351 - val_accuracy: 0.8980\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 6s 64ms/step - loss: 0.0525 - accuracy: 0.9825 - val_loss: 0.3744 - val_accuracy: 0.8878\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 8s 85ms/step - loss: 0.0478 - accuracy: 0.9840 - val_loss: 0.3784 - val_accuracy: 0.8885\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 6s 64ms/step - loss: 0.0471 - accuracy: 0.9830 - val_loss: 0.3616 - val_accuracy: 0.9007\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 7s 78ms/step - loss: 0.0491 - accuracy: 0.9833 - val_loss: 0.3769 - val_accuracy: 0.8892\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 7s 74ms/step - loss: 0.0400 - accuracy: 0.9859 - val_loss: 0.3819 - val_accuracy: 0.8960\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 0.0408 - accuracy: 0.9859 - val_loss: 0.4300 - val_accuracy: 0.8838\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 7s 77ms/step - loss: 0.0507 - accuracy: 0.9821 - val_loss: 0.3799 - val_accuracy: 0.8939\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 6s 65ms/step - loss: 0.0792 - accuracy: 0.9735 - val_loss: 0.4840 - val_accuracy: 0.8742\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 8s 90ms/step - loss: 0.0588 - accuracy: 0.9820 - val_loss: 0.4670 - val_accuracy: 0.8858\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 0.0297 - accuracy: 0.9912 - val_loss: 0.5114 - val_accuracy: 0.8736\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 8s 88ms/step - loss: 0.0366 - accuracy: 0.9886 - val_loss: 0.4523 - val_accuracy: 0.8885\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 6s 64ms/step - loss: 0.0195 - accuracy: 0.9973 - val_loss: 0.4377 - val_accuracy: 0.8960\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.5000 - val_accuracy: 0.8994\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 0.0300 - accuracy: 0.9888 - val_loss: 0.4127 - val_accuracy: 0.8994\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 8s 88ms/step - loss: 0.0176 - accuracy: 0.9954 - val_loss: 0.4840 - val_accuracy: 0.8885\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.0139 - accuracy: 0.9973 - val_loss: 0.4587 - val_accuracy: 0.9001\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 7s 80ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.4600 - val_accuracy: 0.8987\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 6s 66ms/step - loss: 0.0184 - accuracy: 0.9932 - val_loss: 0.4842 - val_accuracy: 0.8953\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 0.0159 - accuracy: 0.9959 - val_loss: 0.5614 - val_accuracy: 0.8885\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 7s 78ms/step - loss: 0.0452 - accuracy: 0.9837 - val_loss: 0.5291 - val_accuracy: 0.8872\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 0.0153 - accuracy: 0.9968 - val_loss: 0.4813 - val_accuracy: 0.8953\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 8s 87ms/step - loss: 0.0110 - accuracy: 0.9980 - val_loss: 0.4909 - val_accuracy: 0.8899\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 0.0082 - accuracy: 0.9993 - val_loss: 0.5044 - val_accuracy: 0.8933\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.5198 - val_accuracy: 0.8851\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 7s 73ms/step - loss: 0.0313 - accuracy: 0.9876 - val_loss: 0.5487 - val_accuracy: 0.8885\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.0231 - accuracy: 0.9917 - val_loss: 0.4970 - val_accuracy: 0.8939\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 6s 63ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.5132 - val_accuracy: 0.8899\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 8s 85ms/step - loss: 0.0059 - accuracy: 0.9993 - val_loss: 0.5003 - val_accuracy: 0.9001\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 6s 64ms/step - loss: 0.0043 - accuracy: 0.9998 - val_loss: 0.5232 - val_accuracy: 0.8926\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 8s 85ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5171 - val_accuracy: 0.8973\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 6s 65ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5289 - val_accuracy: 0.8967\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 7s 78ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5374 - val_accuracy: 0.8967\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5710 - val_accuracy: 0.8967\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 6s 69ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5532 - val_accuracy: 0.8933\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 7s 80ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5584 - val_accuracy: 0.8946\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 6s 64ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5727 - val_accuracy: 0.8967\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5797 - val_accuracy: 0.8953\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 6s 64ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6069 - val_accuracy: 0.8926\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 8s 84ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5871 - val_accuracy: 0.8953\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 6s 63ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6129 - val_accuracy: 0.8933\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 8s 82ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5869 - val_accuracy: 0.8939\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 6s 64ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6096 - val_accuracy: 0.8973\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 7s 73ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6191 - val_accuracy: 0.8973\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 7s 76ms/step - loss: 9.9158e-04 - accuracy: 1.0000 - val_loss: 0.6082 - val_accuracy: 0.8960\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6125 - val_accuracy: 0.8967\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 8s 87ms/step - loss: 9.3026e-04 - accuracy: 1.0000 - val_loss: 0.6085 - val_accuracy: 0.8946\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 8.8509e-04 - accuracy: 1.0000 - val_loss: 0.6434 - val_accuracy: 0.8960\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 7.9858e-04 - accuracy: 1.0000 - val_loss: 0.6333 - val_accuracy: 0.8960\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 7.5098e-04 - accuracy: 1.0000 - val_loss: 0.6696 - val_accuracy: 0.8946\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 7.0524e-04 - accuracy: 1.0000 - val_loss: 0.6669 - val_accuracy: 0.8967\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 6s 64ms/step - loss: 6.4356e-04 - accuracy: 1.0000 - val_loss: 0.6677 - val_accuracy: 0.8946\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 6.5009e-04 - accuracy: 1.0000 - val_loss: 0.6602 - val_accuracy: 0.8973\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 6s 63ms/step - loss: 7.5131e-04 - accuracy: 1.0000 - val_loss: 0.6682 - val_accuracy: 0.8973\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 6.1041e-04 - accuracy: 1.0000 - val_loss: 0.6800 - val_accuracy: 0.8960\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 6s 65ms/step - loss: 5.1396e-04 - accuracy: 1.0000 - val_loss: 0.6941 - val_accuracy: 0.8960\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 7s 80ms/step - loss: 5.2706e-04 - accuracy: 1.0000 - val_loss: 0.6811 - val_accuracy: 0.8933\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 4.4062e-04 - accuracy: 1.0000 - val_loss: 0.7230 - val_accuracy: 0.8933\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 6s 71ms/step - loss: 4.2780e-04 - accuracy: 1.0000 - val_loss: 0.6993 - val_accuracy: 0.8892\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 8s 83ms/step - loss: 4.7104e-04 - accuracy: 1.0000 - val_loss: 0.6936 - val_accuracy: 0.8933\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 6s 69ms/step - loss: 3.6706e-04 - accuracy: 1.0000 - val_loss: 0.6924 - val_accuracy: 0.8973\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 8s 87ms/step - loss: 7.8368e-04 - accuracy: 0.9998 - val_loss: 0.7813 - val_accuracy: 0.8790\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 0.3380 - accuracy: 0.9083 - val_loss: 0.5459 - val_accuracy: 0.8756\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 8s 90ms/step - loss: 0.0486 - accuracy: 0.9818 - val_loss: 0.5841 - val_accuracy: 0.8756\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 0.0273 - accuracy: 0.9910 - val_loss: 0.5836 - val_accuracy: 0.8858\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 8s 85ms/step - loss: 0.0115 - accuracy: 0.9980 - val_loss: 0.5362 - val_accuracy: 0.8946\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 6s 64ms/step - loss: 0.0054 - accuracy: 0.9997 - val_loss: 0.5590 - val_accuracy: 0.9021\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5753 - val_accuracy: 0.8939\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5910 - val_accuracy: 0.8953\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 8s 83ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5931 - val_accuracy: 0.8960\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 6s 65ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5935 - val_accuracy: 0.8960\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 7s 75ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6035 - val_accuracy: 0.8926\n",
            "93/93 [==============================] - 1s 10ms/step - loss: 0.6714 - accuracy: 0.8585\n",
            "Test accuracy of model 2: 0.8585\n",
            "Training model 3\n",
            "Epoch 1/100\n",
            "92/92 [==============================] - 9s 86ms/step - loss: 0.9572 - accuracy: 0.5683 - val_loss: 0.6989 - val_accuracy: 0.6948\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 10s 114ms/step - loss: 0.5966 - accuracy: 0.7494 - val_loss: 0.5729 - val_accuracy: 0.7621\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 7s 73ms/step - loss: 0.4602 - accuracy: 0.8187 - val_loss: 0.4620 - val_accuracy: 0.8396\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 0.3731 - accuracy: 0.8584 - val_loss: 0.4177 - val_accuracy: 0.8457\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 7s 79ms/step - loss: 0.3165 - accuracy: 0.8810 - val_loss: 0.3505 - val_accuracy: 0.8640\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 6s 64ms/step - loss: 0.2601 - accuracy: 0.8995 - val_loss: 0.3805 - val_accuracy: 0.8484\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 0.2243 - accuracy: 0.9163 - val_loss: 0.2920 - val_accuracy: 0.8912\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 6s 65ms/step - loss: 0.1880 - accuracy: 0.9313 - val_loss: 0.2997 - val_accuracy: 0.8844\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 0.1639 - accuracy: 0.9393 - val_loss: 0.3338 - val_accuracy: 0.8783\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 0.1475 - accuracy: 0.9447 - val_loss: 0.3275 - val_accuracy: 0.8858\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 8s 90ms/step - loss: 0.1318 - accuracy: 0.9531 - val_loss: 0.3826 - val_accuracy: 0.8776\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 6s 65ms/step - loss: 0.1372 - accuracy: 0.9476 - val_loss: 0.3578 - val_accuracy: 0.8994\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 8s 84ms/step - loss: 0.1081 - accuracy: 0.9590 - val_loss: 0.3191 - val_accuracy: 0.8892\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 0.0992 - accuracy: 0.9668 - val_loss: 0.3577 - val_accuracy: 0.8946\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 7s 80ms/step - loss: 0.0876 - accuracy: 0.9675 - val_loss: 0.3309 - val_accuracy: 0.8878\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 7s 73ms/step - loss: 0.0852 - accuracy: 0.9665 - val_loss: 0.3733 - val_accuracy: 0.8953\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 7s 75ms/step - loss: 0.0864 - accuracy: 0.9682 - val_loss: 0.3332 - val_accuracy: 0.8939\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 7s 81ms/step - loss: 0.0719 - accuracy: 0.9738 - val_loss: 0.3470 - val_accuracy: 0.9055\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 0.0644 - accuracy: 0.9772 - val_loss: 0.3745 - val_accuracy: 0.8939\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 8s 85ms/step - loss: 0.0549 - accuracy: 0.9808 - val_loss: 0.3616 - val_accuracy: 0.8994\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 6s 66ms/step - loss: 0.0583 - accuracy: 0.9789 - val_loss: 0.3813 - val_accuracy: 0.8919\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 8s 91ms/step - loss: 0.0474 - accuracy: 0.9827 - val_loss: 0.4568 - val_accuracy: 0.8906\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 0.0508 - accuracy: 0.9830 - val_loss: 0.4011 - val_accuracy: 0.8980\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 8s 90ms/step - loss: 0.0383 - accuracy: 0.9867 - val_loss: 0.3975 - val_accuracy: 0.8946\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 6s 69ms/step - loss: 0.0515 - accuracy: 0.9810 - val_loss: 0.4187 - val_accuracy: 0.8980\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 8s 91ms/step - loss: 0.0558 - accuracy: 0.9794 - val_loss: 0.4250 - val_accuracy: 0.8953\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 6s 66ms/step - loss: 0.0315 - accuracy: 0.9915 - val_loss: 0.4967 - val_accuracy: 0.8953\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 8s 87ms/step - loss: 0.0298 - accuracy: 0.9905 - val_loss: 0.4244 - val_accuracy: 0.9001\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 0.0375 - accuracy: 0.9852 - val_loss: 0.4463 - val_accuracy: 0.8994\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 8s 90ms/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.4764 - val_accuracy: 0.9028\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 6s 69ms/step - loss: 0.0232 - accuracy: 0.9930 - val_loss: 0.5429 - val_accuracy: 0.8967\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 8s 87ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.5005 - val_accuracy: 0.8994\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 0.0170 - accuracy: 0.9954 - val_loss: 0.4724 - val_accuracy: 0.8973\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 8s 83ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.5199 - val_accuracy: 0.8980\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 7s 74ms/step - loss: 0.0099 - accuracy: 0.9988 - val_loss: 0.5059 - val_accuracy: 0.9014\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 7s 81ms/step - loss: 0.0076 - accuracy: 0.9995 - val_loss: 0.5610 - val_accuracy: 0.9001\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 7s 77ms/step - loss: 0.0088 - accuracy: 0.9990 - val_loss: 0.5351 - val_accuracy: 0.9021\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 7s 77ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.5860 - val_accuracy: 0.8994\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 7s 77ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 0.5555 - val_accuracy: 0.9001\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 0.5758 - val_accuracy: 0.8994\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 8s 85ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.5784 - val_accuracy: 0.8939\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.6061 - val_accuracy: 0.8906\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.1285 - accuracy: 0.9560 - val_loss: 0.7577 - val_accuracy: 0.8518\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 6s 65ms/step - loss: 0.0920 - accuracy: 0.9694 - val_loss: 0.7202 - val_accuracy: 0.8661\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.0724 - accuracy: 0.9743 - val_loss: 0.5770 - val_accuracy: 0.8926\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 0.0298 - accuracy: 0.9903 - val_loss: 0.5437 - val_accuracy: 0.9001\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 8s 85ms/step - loss: 0.0139 - accuracy: 0.9969 - val_loss: 0.5545 - val_accuracy: 0.8973\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 6s 64ms/step - loss: 0.0080 - accuracy: 0.9988 - val_loss: 0.5707 - val_accuracy: 0.8994\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.5916 - val_accuracy: 0.9001\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5627 - val_accuracy: 0.9082\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 8s 84ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5709 - val_accuracy: 0.9035\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5888 - val_accuracy: 0.9048\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 7s 81ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5796 - val_accuracy: 0.9082\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 7s 73ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5985 - val_accuracy: 0.9055\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 7s 74ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6114 - val_accuracy: 0.9035\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 7s 79ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6327 - val_accuracy: 0.9048\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 6s 66ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6193 - val_accuracy: 0.9028\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 8s 91ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6240 - val_accuracy: 0.9048\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6441 - val_accuracy: 0.9048\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 8s 91ms/step - loss: 9.9983e-04 - accuracy: 1.0000 - val_loss: 0.6581 - val_accuracy: 0.9035\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 9.3582e-04 - accuracy: 1.0000 - val_loss: 0.6560 - val_accuracy: 0.9021\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 8.8744e-04 - accuracy: 1.0000 - val_loss: 0.6648 - val_accuracy: 0.9035\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 8.1113e-04 - accuracy: 1.0000 - val_loss: 0.6666 - val_accuracy: 0.9035\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 8s 92ms/step - loss: 7.2489e-04 - accuracy: 1.0000 - val_loss: 0.6641 - val_accuracy: 0.9035\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 6s 66ms/step - loss: 7.7227e-04 - accuracy: 1.0000 - val_loss: 0.6711 - val_accuracy: 0.9021\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 8s 90ms/step - loss: 6.9817e-04 - accuracy: 1.0000 - val_loss: 0.6810 - val_accuracy: 0.9028\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 6.1907e-04 - accuracy: 1.0000 - val_loss: 0.6992 - val_accuracy: 0.9014\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 8s 88ms/step - loss: 5.7801e-04 - accuracy: 1.0000 - val_loss: 0.6957 - val_accuracy: 0.9021\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 5.3696e-04 - accuracy: 1.0000 - val_loss: 0.6995 - val_accuracy: 0.9028\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 8s 83ms/step - loss: 4.9918e-04 - accuracy: 1.0000 - val_loss: 0.6921 - val_accuracy: 0.9028\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 4.8019e-04 - accuracy: 1.0000 - val_loss: 0.7054 - val_accuracy: 0.9035\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 7s 76ms/step - loss: 4.4698e-04 - accuracy: 1.0000 - val_loss: 0.7017 - val_accuracy: 0.9035\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 7s 81ms/step - loss: 4.1099e-04 - accuracy: 1.0000 - val_loss: 0.7177 - val_accuracy: 0.9041\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 3.8631e-04 - accuracy: 1.0000 - val_loss: 0.7141 - val_accuracy: 0.9048\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 8s 82ms/step - loss: 3.6813e-04 - accuracy: 1.0000 - val_loss: 0.7201 - val_accuracy: 0.9048\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 3.6324e-04 - accuracy: 1.0000 - val_loss: 0.7212 - val_accuracy: 0.9028\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 8s 88ms/step - loss: 3.2443e-04 - accuracy: 1.0000 - val_loss: 0.7459 - val_accuracy: 0.9035\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 6s 71ms/step - loss: 3.1013e-04 - accuracy: 1.0000 - val_loss: 0.7478 - val_accuracy: 0.9035\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 8s 92ms/step - loss: 2.8860e-04 - accuracy: 1.0000 - val_loss: 0.7500 - val_accuracy: 0.9041\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 2.7487e-04 - accuracy: 1.0000 - val_loss: 0.7535 - val_accuracy: 0.9035\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 8s 92ms/step - loss: 2.5468e-04 - accuracy: 1.0000 - val_loss: 0.7639 - val_accuracy: 0.9021\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 2.4828e-04 - accuracy: 1.0000 - val_loss: 0.7675 - val_accuracy: 0.9021\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 8s 91ms/step - loss: 2.3411e-04 - accuracy: 1.0000 - val_loss: 0.7594 - val_accuracy: 0.9028\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 6s 66ms/step - loss: 2.3388e-04 - accuracy: 1.0000 - val_loss: 0.7805 - val_accuracy: 0.9041\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 8s 85ms/step - loss: 2.1208e-04 - accuracy: 1.0000 - val_loss: 0.7682 - val_accuracy: 0.9041\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 7s 70ms/step - loss: 2.0397e-04 - accuracy: 1.0000 - val_loss: 0.7701 - val_accuracy: 0.9035\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 7s 79ms/step - loss: 2.0317e-04 - accuracy: 1.0000 - val_loss: 0.7857 - val_accuracy: 0.9041\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 7s 81ms/step - loss: 1.7850e-04 - accuracy: 1.0000 - val_loss: 0.7821 - val_accuracy: 0.9028\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 7s 73ms/step - loss: 1.7483e-04 - accuracy: 1.0000 - val_loss: 0.7957 - val_accuracy: 0.9021\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 7s 80ms/step - loss: 1.5609e-04 - accuracy: 1.0000 - val_loss: 0.7908 - val_accuracy: 0.9028\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 6s 66ms/step - loss: 1.4989e-04 - accuracy: 1.0000 - val_loss: 0.7982 - val_accuracy: 0.9028\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 8s 92ms/step - loss: 1.4308e-04 - accuracy: 1.0000 - val_loss: 0.8219 - val_accuracy: 0.9021\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 6s 71ms/step - loss: 1.3299e-04 - accuracy: 1.0000 - val_loss: 0.8137 - val_accuracy: 0.9035\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 1.3365e-04 - accuracy: 1.0000 - val_loss: 0.8154 - val_accuracy: 0.9021\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 1.2197e-04 - accuracy: 1.0000 - val_loss: 0.8259 - val_accuracy: 0.9041\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 8s 92ms/step - loss: 1.1631e-04 - accuracy: 1.0000 - val_loss: 0.8379 - val_accuracy: 0.9048\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 6s 66ms/step - loss: 1.1001e-04 - accuracy: 1.0000 - val_loss: 0.8244 - val_accuracy: 0.9021\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 9.9611e-05 - accuracy: 1.0000 - val_loss: 0.8448 - val_accuracy: 0.9028\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 9.4449e-05 - accuracy: 1.0000 - val_loss: 0.8214 - val_accuracy: 0.9028\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 8s 85ms/step - loss: 9.2918e-05 - accuracy: 1.0000 - val_loss: 0.8414 - val_accuracy: 0.9021\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.8806 - accuracy: 0.8575\n",
            "Test accuracy of model 3: 0.8575\n",
            "Training model 4\n",
            "Epoch 1/100\n",
            "92/92 [==============================] - 7s 70ms/step - loss: 1.0431 - accuracy: 0.5249 - val_loss: 0.8036 - val_accuracy: 0.6472\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.6963 - accuracy: 0.7126 - val_loss: 0.5790 - val_accuracy: 0.7859\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 0.5266 - accuracy: 0.7922 - val_loss: 0.5156 - val_accuracy: 0.7906\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.4337 - accuracy: 0.8386 - val_loss: 0.4090 - val_accuracy: 0.8606\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.3515 - accuracy: 0.8709 - val_loss: 0.3637 - val_accuracy: 0.8620\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 8s 82ms/step - loss: 0.3092 - accuracy: 0.8818 - val_loss: 0.3590 - val_accuracy: 0.8627\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 7s 74ms/step - loss: 0.2659 - accuracy: 0.9019 - val_loss: 0.3212 - val_accuracy: 0.8783\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 7s 78ms/step - loss: 0.2412 - accuracy: 0.9095 - val_loss: 0.3127 - val_accuracy: 0.8810\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 8s 81ms/step - loss: 0.2116 - accuracy: 0.9194 - val_loss: 0.2888 - val_accuracy: 0.8865\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 7s 74ms/step - loss: 0.1840 - accuracy: 0.9342 - val_loss: 0.2737 - val_accuracy: 0.8973\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 7s 80ms/step - loss: 0.1675 - accuracy: 0.9388 - val_loss: 0.2845 - val_accuracy: 0.8946\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 0.1550 - accuracy: 0.9437 - val_loss: 0.3018 - val_accuracy: 0.8919\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.1438 - accuracy: 0.9464 - val_loss: 0.3203 - val_accuracy: 0.8804\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 6s 66ms/step - loss: 0.1194 - accuracy: 0.9589 - val_loss: 0.2553 - val_accuracy: 0.9103\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.1210 - accuracy: 0.9534 - val_loss: 0.2613 - val_accuracy: 0.9082\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 0.1056 - accuracy: 0.9624 - val_loss: 0.3350 - val_accuracy: 0.8790\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.0978 - accuracy: 0.9653 - val_loss: 0.2546 - val_accuracy: 0.9123\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 0.0931 - accuracy: 0.9670 - val_loss: 0.2648 - val_accuracy: 0.9069\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.0860 - accuracy: 0.9663 - val_loss: 0.2624 - val_accuracy: 0.9075\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 6s 69ms/step - loss: 0.0821 - accuracy: 0.9704 - val_loss: 0.3031 - val_accuracy: 0.9035\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.0737 - accuracy: 0.9747 - val_loss: 0.2635 - val_accuracy: 0.9069\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.0635 - accuracy: 0.9791 - val_loss: 0.3106 - val_accuracy: 0.8967\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 8s 82ms/step - loss: 0.0624 - accuracy: 0.9796 - val_loss: 0.3073 - val_accuracy: 0.9041\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 7s 73ms/step - loss: 0.0578 - accuracy: 0.9813 - val_loss: 0.2739 - val_accuracy: 0.9130\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 7s 77ms/step - loss: 0.0561 - accuracy: 0.9787 - val_loss: 0.3141 - val_accuracy: 0.9096\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 8s 82ms/step - loss: 0.0433 - accuracy: 0.9876 - val_loss: 0.3021 - val_accuracy: 0.9014\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 7s 75ms/step - loss: 0.0610 - accuracy: 0.9794 - val_loss: 0.3106 - val_accuracy: 0.9048\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 8s 82ms/step - loss: 0.0485 - accuracy: 0.9835 - val_loss: 0.3263 - val_accuracy: 0.9021\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 0.0412 - accuracy: 0.9861 - val_loss: 0.3295 - val_accuracy: 0.9130\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 8s 85ms/step - loss: 0.0368 - accuracy: 0.9884 - val_loss: 0.3443 - val_accuracy: 0.9035\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.0370 - accuracy: 0.9879 - val_loss: 0.3301 - val_accuracy: 0.9103\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 8s 88ms/step - loss: 0.0282 - accuracy: 0.9920 - val_loss: 0.3202 - val_accuracy: 0.9075\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 6s 71ms/step - loss: 0.0295 - accuracy: 0.9910 - val_loss: 0.3400 - val_accuracy: 0.9041\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 8s 88ms/step - loss: 0.0284 - accuracy: 0.9920 - val_loss: 0.3176 - val_accuracy: 0.9089\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.0221 - accuracy: 0.9946 - val_loss: 0.3556 - val_accuracy: 0.9055\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 8s 87ms/step - loss: 0.0215 - accuracy: 0.9939 - val_loss: 0.3459 - val_accuracy: 0.9089\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 0.0537 - accuracy: 0.9804 - val_loss: 0.3883 - val_accuracy: 0.8987\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 8s 83ms/step - loss: 0.0843 - accuracy: 0.9736 - val_loss: 0.4742 - val_accuracy: 0.8797\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 7s 76ms/step - loss: 0.0334 - accuracy: 0.9917 - val_loss: 0.3787 - val_accuracy: 0.9048\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 7s 79ms/step - loss: 0.0165 - accuracy: 0.9976 - val_loss: 0.4427 - val_accuracy: 0.8967\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 7s 81ms/step - loss: 0.0292 - accuracy: 0.9923 - val_loss: 0.4831 - val_accuracy: 0.8804\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 7s 76ms/step - loss: 0.0214 - accuracy: 0.9951 - val_loss: 0.3844 - val_accuracy: 0.9082\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 7s 79ms/step - loss: 0.0085 - accuracy: 0.9993 - val_loss: 0.3953 - val_accuracy: 0.9055\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 0.0070 - accuracy: 0.9998 - val_loss: 0.4036 - val_accuracy: 0.9123\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 8s 83ms/step - loss: 0.0072 - accuracy: 0.9997 - val_loss: 0.4130 - val_accuracy: 0.9116\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 6s 66ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4088 - val_accuracy: 0.9150\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 8s 92ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 0.4295 - val_accuracy: 0.9130\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 6s 71ms/step - loss: 0.0052 - accuracy: 0.9998 - val_loss: 0.4296 - val_accuracy: 0.9109\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 0.4584 - val_accuracy: 0.9028\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 0.0248 - accuracy: 0.9918 - val_loss: 0.5594 - val_accuracy: 0.8953\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.0394 - accuracy: 0.9864 - val_loss: 0.5453 - val_accuracy: 0.8912\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 0.0565 - accuracy: 0.9808 - val_loss: 0.5180 - val_accuracy: 0.8776\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 9s 94ms/step - loss: 0.0737 - accuracy: 0.9719 - val_loss: 0.5602 - val_accuracy: 0.8797\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.0281 - accuracy: 0.9910 - val_loss: 0.4168 - val_accuracy: 0.9150\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 7s 81ms/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 0.4416 - val_accuracy: 0.9069\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.9082\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4367 - val_accuracy: 0.9130\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 7s 78ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4365 - val_accuracy: 0.9157\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 7s 80ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.9157\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 7s 80ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.9150\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 7s 76ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4552 - val_accuracy: 0.9130\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 7s 80ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.9123\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4487 - val_accuracy: 0.9184\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 8s 85ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4698 - val_accuracy: 0.9116\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 6s 71ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4595 - val_accuracy: 0.9164\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4584 - val_accuracy: 0.9157\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4709 - val_accuracy: 0.9143\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 8s 91ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4612 - val_accuracy: 0.9171\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 9.7869e-04 - accuracy: 1.0000 - val_loss: 0.4864 - val_accuracy: 0.9123\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 9.2583e-04 - accuracy: 1.0000 - val_loss: 0.4763 - val_accuracy: 0.9191\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 8.8393e-04 - accuracy: 1.0000 - val_loss: 0.4932 - val_accuracy: 0.9130\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 8s 85ms/step - loss: 8.1938e-04 - accuracy: 1.0000 - val_loss: 0.4891 - val_accuracy: 0.9143\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 7s 75ms/step - loss: 7.9809e-04 - accuracy: 1.0000 - val_loss: 0.4913 - val_accuracy: 0.9150\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 8s 82ms/step - loss: 7.2246e-04 - accuracy: 1.0000 - val_loss: 0.5020 - val_accuracy: 0.9137\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 7s 78ms/step - loss: 6.8684e-04 - accuracy: 1.0000 - val_loss: 0.4940 - val_accuracy: 0.9150\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 7s 77ms/step - loss: 6.5479e-04 - accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.9150\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 7s 78ms/step - loss: 6.1062e-04 - accuracy: 1.0000 - val_loss: 0.5047 - val_accuracy: 0.9164\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 6s 71ms/step - loss: 6.0780e-04 - accuracy: 1.0000 - val_loss: 0.5295 - val_accuracy: 0.9123\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 8s 84ms/step - loss: 5.6027e-04 - accuracy: 1.0000 - val_loss: 0.5095 - val_accuracy: 0.9137\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 5.7173e-04 - accuracy: 1.0000 - val_loss: 0.5191 - val_accuracy: 0.9109\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 8s 92ms/step - loss: 4.9228e-04 - accuracy: 1.0000 - val_loss: 0.5241 - val_accuracy: 0.9143\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 6s 69ms/step - loss: 4.3892e-04 - accuracy: 1.0000 - val_loss: 0.5330 - val_accuracy: 0.9137\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 9s 93ms/step - loss: 4.3688e-04 - accuracy: 1.0000 - val_loss: 0.5322 - val_accuracy: 0.9109\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 4.3191e-04 - accuracy: 1.0000 - val_loss: 0.5380 - val_accuracy: 0.9157\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 8s 88ms/step - loss: 3.8008e-04 - accuracy: 1.0000 - val_loss: 0.5332 - val_accuracy: 0.9123\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 3.8661e-04 - accuracy: 1.0000 - val_loss: 0.5412 - val_accuracy: 0.9143\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 3.6692e-04 - accuracy: 1.0000 - val_loss: 0.5586 - val_accuracy: 0.9123\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 6s 69ms/step - loss: 3.3110e-04 - accuracy: 1.0000 - val_loss: 0.5513 - val_accuracy: 0.9130\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 8s 84ms/step - loss: 3.2972e-04 - accuracy: 1.0000 - val_loss: 0.5543 - val_accuracy: 0.9109\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 2.9475e-04 - accuracy: 1.0000 - val_loss: 0.5653 - val_accuracy: 0.9116\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 7s 78ms/step - loss: 2.8887e-04 - accuracy: 1.0000 - val_loss: 0.5606 - val_accuracy: 0.9143\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 7s 80ms/step - loss: 2.5478e-04 - accuracy: 1.0000 - val_loss: 0.5662 - val_accuracy: 0.9123\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 7s 75ms/step - loss: 2.4829e-04 - accuracy: 1.0000 - val_loss: 0.5644 - val_accuracy: 0.9130\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 7s 79ms/step - loss: 2.3438e-04 - accuracy: 1.0000 - val_loss: 0.5689 - val_accuracy: 0.9103\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 2.2645e-04 - accuracy: 1.0000 - val_loss: 0.5878 - val_accuracy: 0.9123\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 8s 88ms/step - loss: 2.1058e-04 - accuracy: 1.0000 - val_loss: 0.5776 - val_accuracy: 0.9150\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 1.9861e-04 - accuracy: 1.0000 - val_loss: 0.5809 - val_accuracy: 0.9109\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 8s 93ms/step - loss: 1.9870e-04 - accuracy: 1.0000 - val_loss: 0.5937 - val_accuracy: 0.9123\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 1.8340e-04 - accuracy: 1.0000 - val_loss: 0.5878 - val_accuracy: 0.9143\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 1.7425e-04 - accuracy: 1.0000 - val_loss: 0.6088 - val_accuracy: 0.9130\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.8613 - accuracy: 0.8660\n",
            "Test accuracy of model 4: 0.8660\n",
            "Training model 5\n",
            "Epoch 1/100\n",
            "92/92 [==============================] - 9s 80ms/step - loss: 1.0218 - accuracy: 0.5372 - val_loss: 0.8234 - val_accuracy: 0.6193\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 7s 77ms/step - loss: 0.6404 - accuracy: 0.7352 - val_loss: 0.5887 - val_accuracy: 0.7729\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 7s 80ms/step - loss: 0.5025 - accuracy: 0.8072 - val_loss: 0.5088 - val_accuracy: 0.7627\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 7s 73ms/step - loss: 0.3926 - accuracy: 0.8534 - val_loss: 0.4268 - val_accuracy: 0.8219\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 8s 85ms/step - loss: 0.3295 - accuracy: 0.8820 - val_loss: 0.3631 - val_accuracy: 0.8613\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.2684 - accuracy: 0.9022 - val_loss: 0.3647 - val_accuracy: 0.8722\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 8s 92ms/step - loss: 0.2392 - accuracy: 0.9150 - val_loss: 0.2950 - val_accuracy: 0.8953\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 0.2019 - accuracy: 0.9250 - val_loss: 0.3265 - val_accuracy: 0.8797\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 8s 92ms/step - loss: 0.1623 - accuracy: 0.9434 - val_loss: 0.3157 - val_accuracy: 0.8797\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.1624 - accuracy: 0.9407 - val_loss: 0.3454 - val_accuracy: 0.8790\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 8s 92ms/step - loss: 0.1469 - accuracy: 0.9456 - val_loss: 0.3048 - val_accuracy: 0.8912\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 0.1209 - accuracy: 0.9568 - val_loss: 0.3022 - val_accuracy: 0.8980\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 8s 90ms/step - loss: 0.1321 - accuracy: 0.9481 - val_loss: 0.3113 - val_accuracy: 0.8939\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 0.0941 - accuracy: 0.9667 - val_loss: 0.2901 - val_accuracy: 0.9082\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 8s 84ms/step - loss: 0.0909 - accuracy: 0.9655 - val_loss: 0.2843 - val_accuracy: 0.9055\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 0.0730 - accuracy: 0.9755 - val_loss: 0.3416 - val_accuracy: 0.8926\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 7s 78ms/step - loss: 0.0679 - accuracy: 0.9781 - val_loss: 0.3066 - val_accuracy: 0.9021\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 7s 79ms/step - loss: 0.0588 - accuracy: 0.9813 - val_loss: 0.3316 - val_accuracy: 0.9028\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 7s 74ms/step - loss: 0.0583 - accuracy: 0.9815 - val_loss: 0.3438 - val_accuracy: 0.8953\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 8s 84ms/step - loss: 0.0544 - accuracy: 0.9832 - val_loss: 0.3607 - val_accuracy: 0.8885\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 0.0516 - accuracy: 0.9813 - val_loss: 0.3494 - val_accuracy: 0.9035\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 8s 87ms/step - loss: 0.0573 - accuracy: 0.9777 - val_loss: 0.3494 - val_accuracy: 0.9014\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 6s 67ms/step - loss: 0.0512 - accuracy: 0.9828 - val_loss: 0.3880 - val_accuracy: 0.8906\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.0436 - accuracy: 0.9838 - val_loss: 0.3362 - val_accuracy: 0.8994\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 0.0355 - accuracy: 0.9878 - val_loss: 0.3824 - val_accuracy: 0.9035\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 8s 90ms/step - loss: 0.0288 - accuracy: 0.9917 - val_loss: 0.3637 - val_accuracy: 0.9021\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 0.0284 - accuracy: 0.9917 - val_loss: 0.4052 - val_accuracy: 0.9001\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.0275 - accuracy: 0.9900 - val_loss: 0.3582 - val_accuracy: 0.9035\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 0.0320 - accuracy: 0.9900 - val_loss: 0.4337 - val_accuracy: 0.8831\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 8s 87ms/step - loss: 0.0445 - accuracy: 0.9850 - val_loss: 0.4510 - val_accuracy: 0.8729\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 0.0690 - accuracy: 0.9764 - val_loss: 0.5479 - val_accuracy: 0.8661\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 8s 83ms/step - loss: 0.0547 - accuracy: 0.9811 - val_loss: 0.4894 - val_accuracy: 0.8844\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 7s 76ms/step - loss: 0.0285 - accuracy: 0.9930 - val_loss: 0.4344 - val_accuracy: 0.8933\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 7s 77ms/step - loss: 0.0182 - accuracy: 0.9959 - val_loss: 0.4758 - val_accuracy: 0.9001\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 7s 81ms/step - loss: 0.0188 - accuracy: 0.9961 - val_loss: 0.4939 - val_accuracy: 0.8919\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 7s 73ms/step - loss: 0.0076 - accuracy: 0.9998 - val_loss: 0.4307 - val_accuracy: 0.9089\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.0065 - accuracy: 0.9998 - val_loss: 0.4543 - val_accuracy: 0.9048\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4624 - val_accuracy: 0.9062\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 9s 94ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4495 - val_accuracy: 0.9096\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 6s 69ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4739 - val_accuracy: 0.9116\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 8s 91ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.5616 - val_accuracy: 0.8953\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 6s 69ms/step - loss: 0.0042 - accuracy: 0.9997 - val_loss: 0.4918 - val_accuracy: 0.9014\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 9s 94ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4835 - val_accuracy: 0.9062\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5198 - val_accuracy: 0.9048\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 9s 94ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5240 - val_accuracy: 0.8980\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 7s 73ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.5465 - val_accuracy: 0.8967\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 8s 93ms/step - loss: 0.1257 - accuracy: 0.9634 - val_loss: 0.5509 - val_accuracy: 0.8736\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 0.0707 - accuracy: 0.9748 - val_loss: 0.4287 - val_accuracy: 0.8973\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 0.0157 - accuracy: 0.9968 - val_loss: 0.4362 - val_accuracy: 0.9048\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 7s 75ms/step - loss: 0.0485 - accuracy: 0.9845 - val_loss: 0.5304 - val_accuracy: 0.8817\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 8s 84ms/step - loss: 0.0350 - accuracy: 0.9888 - val_loss: 0.4184 - val_accuracy: 0.9150\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 7s 76ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.4419 - val_accuracy: 0.9055\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 7s 80ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4570 - val_accuracy: 0.9096\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 7s 79ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4636 - val_accuracy: 0.9109\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 7s 75ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4681 - val_accuracy: 0.9116\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 8s 83ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4743 - val_accuracy: 0.9069\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4877 - val_accuracy: 0.9109\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4933 - val_accuracy: 0.9069\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5023 - val_accuracy: 0.9062\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 9s 93ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5084 - val_accuracy: 0.9075\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 6s 69ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5034 - val_accuracy: 0.9089\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5126 - val_accuracy: 0.9116\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 6s 69ms/step - loss: 9.8028e-04 - accuracy: 1.0000 - val_loss: 0.5133 - val_accuracy: 0.9089\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 9.1977e-04 - accuracy: 1.0000 - val_loss: 0.5233 - val_accuracy: 0.9069\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 8.0940e-04 - accuracy: 1.0000 - val_loss: 0.5287 - val_accuracy: 0.9082\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 8s 87ms/step - loss: 7.4029e-04 - accuracy: 1.0000 - val_loss: 0.5438 - val_accuracy: 0.9075\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 6.9429e-04 - accuracy: 1.0000 - val_loss: 0.5405 - val_accuracy: 0.9075\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 8s 83ms/step - loss: 6.4014e-04 - accuracy: 1.0000 - val_loss: 0.5451 - val_accuracy: 0.9089\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 7s 75ms/step - loss: 6.1467e-04 - accuracy: 1.0000 - val_loss: 0.5552 - val_accuracy: 0.9069\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 7s 79ms/step - loss: 5.5129e-04 - accuracy: 1.0000 - val_loss: 0.5549 - val_accuracy: 0.9082\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 7s 81ms/step - loss: 5.3792e-04 - accuracy: 1.0000 - val_loss: 0.5530 - val_accuracy: 0.9082\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 7s 73ms/step - loss: 5.1542e-04 - accuracy: 1.0000 - val_loss: 0.5576 - val_accuracy: 0.9075\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 4.8354e-04 - accuracy: 1.0000 - val_loss: 0.5673 - val_accuracy: 0.9082\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 4.3640e-04 - accuracy: 1.0000 - val_loss: 0.5743 - val_accuracy: 0.9075\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 8s 90ms/step - loss: 4.1026e-04 - accuracy: 1.0000 - val_loss: 0.5710 - val_accuracy: 0.9082\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 6s 68ms/step - loss: 4.0419e-04 - accuracy: 1.0000 - val_loss: 0.5860 - val_accuracy: 0.9069\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 9s 93ms/step - loss: 3.6613e-04 - accuracy: 1.0000 - val_loss: 0.5986 - val_accuracy: 0.9069\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 3.6213e-04 - accuracy: 1.0000 - val_loss: 0.6044 - val_accuracy: 0.9089\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 9s 94ms/step - loss: 3.3285e-04 - accuracy: 1.0000 - val_loss: 0.6010 - val_accuracy: 0.9075\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 3.0218e-04 - accuracy: 1.0000 - val_loss: 0.6091 - val_accuracy: 0.9062\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 8s 93ms/step - loss: 2.9395e-04 - accuracy: 1.0000 - val_loss: 0.6113 - val_accuracy: 0.9048\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 6s 69ms/step - loss: 2.8136e-04 - accuracy: 1.0000 - val_loss: 0.6181 - val_accuracy: 0.9089\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 8s 88ms/step - loss: 2.6442e-04 - accuracy: 1.0000 - val_loss: 0.6139 - val_accuracy: 0.9075\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 2.5317e-04 - accuracy: 1.0000 - val_loss: 0.6383 - val_accuracy: 0.9089\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 8s 83ms/step - loss: 2.3953e-04 - accuracy: 1.0000 - val_loss: 0.6249 - val_accuracy: 0.9069\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 8s 82ms/step - loss: 2.2504e-04 - accuracy: 1.0000 - val_loss: 0.6384 - val_accuracy: 0.9048\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 8s 82ms/step - loss: 2.1022e-04 - accuracy: 1.0000 - val_loss: 0.6367 - val_accuracy: 0.9062\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 7s 78ms/step - loss: 2.0199e-04 - accuracy: 1.0000 - val_loss: 0.6358 - val_accuracy: 0.9075\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 7s 76ms/step - loss: 1.9019e-04 - accuracy: 1.0000 - val_loss: 0.6450 - val_accuracy: 0.9062\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 8s 87ms/step - loss: 1.7836e-04 - accuracy: 1.0000 - val_loss: 0.6626 - val_accuracy: 0.9089\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 7s 75ms/step - loss: 1.7451e-04 - accuracy: 1.0000 - val_loss: 0.6525 - val_accuracy: 0.9062\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 1.6611e-04 - accuracy: 1.0000 - val_loss: 0.6628 - val_accuracy: 0.9082\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 7s 73ms/step - loss: 1.5623e-04 - accuracy: 1.0000 - val_loss: 0.6590 - val_accuracy: 0.9062\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 8s 88ms/step - loss: 1.4391e-04 - accuracy: 1.0000 - val_loss: 0.6780 - val_accuracy: 0.9041\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 6s 69ms/step - loss: 1.2953e-04 - accuracy: 1.0000 - val_loss: 0.6696 - val_accuracy: 0.9062\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 8s 91ms/step - loss: 1.2481e-04 - accuracy: 1.0000 - val_loss: 0.6879 - val_accuracy: 0.9035\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 7s 73ms/step - loss: 1.1897e-04 - accuracy: 1.0000 - val_loss: 0.6914 - val_accuracy: 0.9082\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 8s 91ms/step - loss: 1.1583e-04 - accuracy: 1.0000 - val_loss: 0.6802 - val_accuracy: 0.9075\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 6s 69ms/step - loss: 1.1309e-04 - accuracy: 1.0000 - val_loss: 0.7030 - val_accuracy: 0.9048\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 8s 90ms/step - loss: 1.0897e-04 - accuracy: 1.0000 - val_loss: 0.6970 - val_accuracy: 0.9075\n",
            "93/93 [==============================] - 1s 11ms/step - loss: 0.7333 - accuracy: 0.8806\n",
            "Test accuracy of model 5: 0.8806\n",
            "Training model 1...\n",
            "Epoch 1/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 0.4364 - accuracy: 0.8313 - val_loss: 0.1680 - val_accuracy: 0.9368\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 9s 93ms/step - loss: 0.1157 - accuracy: 0.9606 - val_loss: 0.1154 - val_accuracy: 0.9456\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 7s 75ms/step - loss: 0.0660 - accuracy: 0.9793 - val_loss: 0.1246 - val_accuracy: 0.9558\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 8s 92ms/step - loss: 0.0552 - accuracy: 0.9823 - val_loss: 0.1036 - val_accuracy: 0.9531\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 7s 74ms/step - loss: 0.0427 - accuracy: 0.9842 - val_loss: 0.0984 - val_accuracy: 0.9558\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 9s 95ms/step - loss: 0.0491 - accuracy: 0.9828 - val_loss: 0.1120 - val_accuracy: 0.9538\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 0.0337 - accuracy: 0.9874 - val_loss: 0.1118 - val_accuracy: 0.9558\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 8s 92ms/step - loss: 0.0258 - accuracy: 0.9910 - val_loss: 0.0988 - val_accuracy: 0.9599\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 6s 71ms/step - loss: 0.0255 - accuracy: 0.9908 - val_loss: 0.1178 - val_accuracy: 0.9517\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 8s 90ms/step - loss: 0.0223 - accuracy: 0.9934 - val_loss: 0.1061 - val_accuracy: 0.9585\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 0.0229 - accuracy: 0.9913 - val_loss: 0.1181 - val_accuracy: 0.9619\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.1057 - val_accuracy: 0.9606\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 7s 79ms/step - loss: 0.0150 - accuracy: 0.9946 - val_loss: 0.1224 - val_accuracy: 0.9633\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 8s 84ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.1225 - val_accuracy: 0.9626\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 7s 77ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.1155 - val_accuracy: 0.9653\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 7s 80ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.1112 - val_accuracy: 0.9660\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 8s 84ms/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 0.1294 - val_accuracy: 0.9572\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 0.0090 - accuracy: 0.9978 - val_loss: 0.1143 - val_accuracy: 0.9653\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 8s 85ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.1440 - val_accuracy: 0.9565\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 7s 81ms/step - loss: 0.0128 - accuracy: 0.9949 - val_loss: 0.1779 - val_accuracy: 0.9613\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 0.0113 - accuracy: 0.9954 - val_loss: 0.1264 - val_accuracy: 0.9619\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 7s 78ms/step - loss: 0.0160 - accuracy: 0.9934 - val_loss: 0.1832 - val_accuracy: 0.9606\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 0.0089 - accuracy: 0.9966 - val_loss: 0.1720 - val_accuracy: 0.9646\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 7s 76ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.1301 - val_accuracy: 0.9640\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.1408 - val_accuracy: 0.9667\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.1378 - val_accuracy: 0.9626\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 9s 94ms/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 0.2028 - val_accuracy: 0.9606\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.1447 - val_accuracy: 0.9660\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 8s 91ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.1777 - val_accuracy: 0.9653\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 7s 74ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.1910 - val_accuracy: 0.9660\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 8s 92ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.1542 - val_accuracy: 0.9619\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.1509 - val_accuracy: 0.9660\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 9s 96ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.1798 - val_accuracy: 0.9680\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 7s 74ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1521 - val_accuracy: 0.9667\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 9s 96ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1378 - val_accuracy: 0.9694\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 7s 74ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1536 - val_accuracy: 0.9660\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 8s 91ms/step - loss: 0.0386 - accuracy: 0.9883 - val_loss: 0.2565 - val_accuracy: 0.9273\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 6s 69ms/step - loss: 0.0526 - accuracy: 0.9815 - val_loss: 0.1711 - val_accuracy: 0.9558\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 8s 90ms/step - loss: 0.0091 - accuracy: 0.9964 - val_loss: 0.1719 - val_accuracy: 0.9558\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 7s 72ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.1519 - val_accuracy: 0.9626\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 8s 85ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9653\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 7s 77ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.1604 - val_accuracy: 0.9633\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 8s 82ms/step - loss: 9.9261e-04 - accuracy: 1.0000 - val_loss: 0.1618 - val_accuracy: 0.9653\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 7s 79ms/step - loss: 7.6189e-04 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9646\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 7s 78ms/step - loss: 6.4417e-04 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 0.9646\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 8s 83ms/step - loss: 8.1709e-04 - accuracy: 1.0000 - val_loss: 0.1621 - val_accuracy: 0.9646\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 7s 75ms/step - loss: 5.4606e-04 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9646\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 8s 90ms/step - loss: 5.0294e-04 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9646\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 7s 74ms/step - loss: 5.8488e-04 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9640\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 8s 88ms/step - loss: 4.0484e-04 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 0.9660\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 7s 74ms/step - loss: 4.0040e-04 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9653\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 9s 95ms/step - loss: 3.8357e-04 - accuracy: 1.0000 - val_loss: 0.1732 - val_accuracy: 0.9660\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 7s 74ms/step - loss: 3.1538e-04 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9653\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 8s 91ms/step - loss: 3.1889e-04 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.9653\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 2.8414e-04 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9660\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 8s 91ms/step - loss: 3.1217e-04 - accuracy: 1.0000 - val_loss: 0.1731 - val_accuracy: 0.9667\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 6s 71ms/step - loss: 2.6170e-04 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9674\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 9s 93ms/step - loss: 2.0728e-04 - accuracy: 1.0000 - val_loss: 0.1805 - val_accuracy: 0.9667\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 2.2466e-04 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9667\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 8s 92ms/step - loss: 1.8005e-04 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9660\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 1.7887e-04 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9674\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 8s 87ms/step - loss: 1.8302e-04 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9667\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 7s 74ms/step - loss: 1.8261e-04 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9660\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 8s 83ms/step - loss: 1.4209e-04 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9660\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 7s 79ms/step - loss: 1.5387e-04 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9667\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 8s 82ms/step - loss: 2.4198e-04 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9660\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 7s 81ms/step - loss: 1.5608e-04 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9660\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 7s 77ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 0.3175 - val_accuracy: 0.9619\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 8s 84ms/step - loss: 0.0395 - accuracy: 0.9879 - val_loss: 0.2564 - val_accuracy: 0.9463\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 0.1620 - val_accuracy: 0.9599\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 8s 92ms/step - loss: 0.0082 - accuracy: 0.9964 - val_loss: 0.1979 - val_accuracy: 0.9660\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.1704 - val_accuracy: 0.9640\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 8s 91ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.2251 - val_accuracy: 0.9572\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 7s 74ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.1870 - val_accuracy: 0.9599\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 9s 95ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.1806 - val_accuracy: 0.9667\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 6s 69ms/step - loss: 6.1778e-04 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9653\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 8s 92ms/step - loss: 4.9181e-04 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9674\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 3.7231e-04 - accuracy: 1.0000 - val_loss: 0.1760 - val_accuracy: 0.9680\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 9s 95ms/step - loss: 4.1262e-04 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9687\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 3.8451e-04 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 0.9653\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 8s 91ms/step - loss: 2.7570e-04 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9667\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 6s 71ms/step - loss: 2.5967e-04 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9687\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 9s 96ms/step - loss: 2.6758e-04 - accuracy: 1.0000 - val_loss: 0.1680 - val_accuracy: 0.9667\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 7s 71ms/step - loss: 2.0440e-04 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9687\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 8s 90ms/step - loss: 1.9149e-04 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 0.9667\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 7s 76ms/step - loss: 1.8000e-04 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.9680\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 8s 89ms/step - loss: 1.7004e-04 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 0.9680\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 7s 76ms/step - loss: 1.6988e-04 - accuracy: 1.0000 - val_loss: 0.1719 - val_accuracy: 0.9687\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 8s 84ms/step - loss: 1.7435e-04 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9701\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 7s 77ms/step - loss: 1.4815e-04 - accuracy: 1.0000 - val_loss: 0.1756 - val_accuracy: 0.9680\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 7s 81ms/step - loss: 1.2479e-04 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 0.9674\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 1.1871e-04 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9674\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 7s 78ms/step - loss: 1.0105e-04 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9667\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 8s 87ms/step - loss: 9.3530e-05 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9667\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 7s 77ms/step - loss: 1.1996e-04 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9667\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 8s 86ms/step - loss: 1.1010e-04 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9660\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 7s 74ms/step - loss: 9.6783e-05 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.9667\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 8s 92ms/step - loss: 7.3944e-05 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9674\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 7s 75ms/step - loss: 7.9758e-05 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9660\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 9s 92ms/step - loss: 6.8187e-05 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9680\n",
            "Training model 2...\n",
            "Epoch 1/100\n",
            "92/92 [==============================] - 4s 38ms/step - loss: 0.5260 - accuracy: 0.8092 - val_loss: 0.1861 - val_accuracy: 0.9422\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 4s 44ms/step - loss: 0.1420 - accuracy: 0.9529 - val_loss: 0.1281 - val_accuracy: 0.9436\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 5s 51ms/step - loss: 0.0927 - accuracy: 0.9677 - val_loss: 0.1116 - val_accuracy: 0.9470\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 0.0625 - accuracy: 0.9825 - val_loss: 0.1119 - val_accuracy: 0.9531\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 0.0467 - accuracy: 0.9855 - val_loss: 0.0971 - val_accuracy: 0.9565\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 4s 43ms/step - loss: 0.0468 - accuracy: 0.9857 - val_loss: 0.1128 - val_accuracy: 0.9517\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 5s 53ms/step - loss: 0.0383 - accuracy: 0.9867 - val_loss: 0.1376 - val_accuracy: 0.9483\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 0.0345 - accuracy: 0.9886 - val_loss: 0.0985 - val_accuracy: 0.9551\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 3s 35ms/step - loss: 0.0316 - accuracy: 0.9883 - val_loss: 0.1045 - val_accuracy: 0.9565\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 4s 40ms/step - loss: 0.0252 - accuracy: 0.9922 - val_loss: 0.1058 - val_accuracy: 0.9551\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 5s 54ms/step - loss: 0.0220 - accuracy: 0.9930 - val_loss: 0.1116 - val_accuracy: 0.9551\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 0.1108 - val_accuracy: 0.9585\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 0.0360 - accuracy: 0.9872 - val_loss: 0.1767 - val_accuracy: 0.9429\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 0.0251 - accuracy: 0.9900 - val_loss: 0.1165 - val_accuracy: 0.9524\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 5s 53ms/step - loss: 0.0194 - accuracy: 0.9946 - val_loss: 0.1202 - val_accuracy: 0.9558\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 4s 43ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 0.1115 - val_accuracy: 0.9592\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 0.0160 - accuracy: 0.9937 - val_loss: 0.1295 - val_accuracy: 0.9572\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 0.0196 - accuracy: 0.9927 - val_loss: 0.1450 - val_accuracy: 0.9511\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 5s 52ms/step - loss: 0.0138 - accuracy: 0.9949 - val_loss: 0.1160 - val_accuracy: 0.9606\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 4s 45ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.1177 - val_accuracy: 0.9626\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.1168 - val_accuracy: 0.9619\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.1241 - val_accuracy: 0.9606\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 4s 47ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.1273 - val_accuracy: 0.9619\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 5s 50ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.1265 - val_accuracy: 0.9606\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 0.1250 - val_accuracy: 0.9606\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 0.1175 - val_accuracy: 0.9653\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 4s 45ms/step - loss: 0.0096 - accuracy: 0.9964 - val_loss: 0.1160 - val_accuracy: 0.9640\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 5s 51ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.1189 - val_accuracy: 0.9633\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.1280 - val_accuracy: 0.9646\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 0.1150 - val_accuracy: 0.9653\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 4s 40ms/step - loss: 0.0147 - accuracy: 0.9939 - val_loss: 0.1531 - val_accuracy: 0.9599\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 5s 58ms/step - loss: 0.0089 - accuracy: 0.9966 - val_loss: 0.1784 - val_accuracy: 0.9572\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 0.0063 - accuracy: 0.9974 - val_loss: 0.1284 - val_accuracy: 0.9660\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.1220 - val_accuracy: 0.9687\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 4s 38ms/step - loss: 0.0059 - accuracy: 0.9971 - val_loss: 0.1464 - val_accuracy: 0.9646\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 5s 57ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.1659 - val_accuracy: 0.9613\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 0.9667\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 0.9619\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9626\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 5s 58ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.1347 - val_accuracy: 0.9660\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.1513 - val_accuracy: 0.9599\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.1422 - val_accuracy: 0.9640\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.1723 - val_accuracy: 0.9626\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 5s 57ms/step - loss: 8.0846e-04 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9680\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 4s 41ms/step - loss: 9.0664e-04 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9674\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 5.6990e-04 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9646\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 3s 38ms/step - loss: 4.9326e-04 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9667\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 5s 53ms/step - loss: 5.2151e-04 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9660\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 4s 44ms/step - loss: 4.4248e-04 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9660\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 8.3826e-04 - accuracy: 1.0000 - val_loss: 0.1571 - val_accuracy: 0.9653\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 3.8632e-04 - accuracy: 1.0000 - val_loss: 0.1589 - val_accuracy: 0.9640\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 4s 47ms/step - loss: 3.2482e-04 - accuracy: 1.0000 - val_loss: 0.1509 - val_accuracy: 0.9667\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 5s 50ms/step - loss: 3.0803e-04 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9646\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 2.9388e-04 - accuracy: 1.0000 - val_loss: 0.1546 - val_accuracy: 0.9653\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 2.7648e-04 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9667\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 4s 42ms/step - loss: 2.5577e-04 - accuracy: 1.0000 - val_loss: 0.1595 - val_accuracy: 0.9653\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 5s 53ms/step - loss: 2.1679e-04 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9667\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 3s 35ms/step - loss: 2.3303e-04 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9660\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 2.2888e-04 - accuracy: 1.0000 - val_loss: 0.1650 - val_accuracy: 0.9660\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 1.8869e-04 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9667\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 5s 55ms/step - loss: 1.7386e-04 - accuracy: 1.0000 - val_loss: 0.1625 - val_accuracy: 0.9660\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 4s 38ms/step - loss: 1.6158e-04 - accuracy: 1.0000 - val_loss: 0.1680 - val_accuracy: 0.9653\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 2.5036e-04 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9660\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 1.8785e-04 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9640\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 5s 54ms/step - loss: 8.9506e-04 - accuracy: 0.9997 - val_loss: 0.1927 - val_accuracy: 0.9626\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 4s 42ms/step - loss: 0.1172 - accuracy: 0.9706 - val_loss: 0.2269 - val_accuracy: 0.9334\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 0.0312 - accuracy: 0.9895 - val_loss: 0.1980 - val_accuracy: 0.9524\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.1973 - val_accuracy: 0.9504\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 5s 49ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.1700 - val_accuracy: 0.9579\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 4s 47ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.1721 - val_accuracy: 0.9592\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.1785 - val_accuracy: 0.9572\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9599\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 4s 48ms/step - loss: 9.4619e-04 - accuracy: 1.0000 - val_loss: 0.1683 - val_accuracy: 0.9592\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 4s 48ms/step - loss: 8.1241e-04 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9592\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 7.8755e-04 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9579\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 6.8889e-04 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9599\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 4s 42ms/step - loss: 5.9858e-04 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 0.9592\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 5s 53ms/step - loss: 5.9437e-04 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9592\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 6.5888e-04 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9606\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 4.9273e-04 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9585\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 4s 41ms/step - loss: 5.3342e-04 - accuracy: 1.0000 - val_loss: 0.1762 - val_accuracy: 0.9606\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 5s 56ms/step - loss: 4.5251e-04 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.9613\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 3.9394e-04 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 0.9613\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 3.7777e-04 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9606\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 4s 42ms/step - loss: 3.9053e-04 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9599\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 5s 55ms/step - loss: 3.0594e-04 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9619\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 3.0649e-04 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9613\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 2.8229e-04 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9619\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 4s 41ms/step - loss: 2.4493e-04 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9613\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 5s 54ms/step - loss: 2.5950e-04 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9613\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 2.6237e-04 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9626\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 2.6376e-04 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9619\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 1.9180e-04 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9613\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 5s 58ms/step - loss: 1.9347e-04 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9619\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 4s 39ms/step - loss: 2.1890e-04 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.9613\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 1.8666e-04 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9613\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 1.8853e-04 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 0.9619\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 5s 56ms/step - loss: 1.4878e-04 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9613\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 4s 42ms/step - loss: 1.5332e-04 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9619\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 1.2845e-04 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9613\n",
            "Training model 3...\n",
            "Epoch 1/100\n",
            "92/92 [==============================] - 19s 194ms/step - loss: 0.5459 - accuracy: 0.8004 - val_loss: 0.1794 - val_accuracy: 0.9368\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 17s 182ms/step - loss: 0.1390 - accuracy: 0.9475 - val_loss: 0.1244 - val_accuracy: 0.9456\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 16s 175ms/step - loss: 0.0729 - accuracy: 0.9777 - val_loss: 0.1108 - val_accuracy: 0.9490\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 16s 175ms/step - loss: 0.0573 - accuracy: 0.9786 - val_loss: 0.1149 - val_accuracy: 0.9517\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 16s 178ms/step - loss: 0.0529 - accuracy: 0.9815 - val_loss: 0.1201 - val_accuracy: 0.9545\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 16s 179ms/step - loss: 0.0385 - accuracy: 0.9866 - val_loss: 0.1548 - val_accuracy: 0.9511\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 17s 180ms/step - loss: 0.0436 - accuracy: 0.9828 - val_loss: 0.1541 - val_accuracy: 0.9436\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 16s 177ms/step - loss: 0.0406 - accuracy: 0.9849 - val_loss: 0.1289 - val_accuracy: 0.9558\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 17s 184ms/step - loss: 0.0332 - accuracy: 0.9867 - val_loss: 0.1503 - val_accuracy: 0.9538\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 17s 189ms/step - loss: 0.0301 - accuracy: 0.9881 - val_loss: 0.1390 - val_accuracy: 0.9477\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 17s 181ms/step - loss: 0.0271 - accuracy: 0.9895 - val_loss: 0.1516 - val_accuracy: 0.9565\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 16s 177ms/step - loss: 0.0231 - accuracy: 0.9905 - val_loss: 0.1345 - val_accuracy: 0.9524\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 17s 181ms/step - loss: 0.0232 - accuracy: 0.9912 - val_loss: 0.1523 - val_accuracy: 0.9456\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 16s 173ms/step - loss: 0.0207 - accuracy: 0.9913 - val_loss: 0.1509 - val_accuracy: 0.9633\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 16s 174ms/step - loss: 0.0174 - accuracy: 0.9929 - val_loss: 0.1501 - val_accuracy: 0.9585\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 16s 179ms/step - loss: 0.0181 - accuracy: 0.9930 - val_loss: 0.1455 - val_accuracy: 0.9585\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 16s 174ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.1604 - val_accuracy: 0.9531\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 16s 172ms/step - loss: 0.0198 - accuracy: 0.9925 - val_loss: 0.1566 - val_accuracy: 0.9538\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 16s 176ms/step - loss: 0.0269 - accuracy: 0.9903 - val_loss: 0.1896 - val_accuracy: 0.9545\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 17s 182ms/step - loss: 0.0538 - accuracy: 0.9816 - val_loss: 0.1653 - val_accuracy: 0.9551\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 17s 188ms/step - loss: 0.0271 - accuracy: 0.9901 - val_loss: 0.1706 - val_accuracy: 0.9579\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 17s 184ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 0.2525 - val_accuracy: 0.9538\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 17s 186ms/step - loss: 0.0173 - accuracy: 0.9930 - val_loss: 0.1705 - val_accuracy: 0.9619\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 17s 183ms/step - loss: 0.0107 - accuracy: 0.9956 - val_loss: 0.1851 - val_accuracy: 0.9619\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 16s 173ms/step - loss: 0.0155 - accuracy: 0.9939 - val_loss: 0.1720 - val_accuracy: 0.9592\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 16s 178ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.1864 - val_accuracy: 0.9626\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 16s 176ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.2088 - val_accuracy: 0.9640\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 17s 186ms/step - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.2074 - val_accuracy: 0.9619\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 17s 179ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.2230 - val_accuracy: 0.9626\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 17s 183ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.1725 - val_accuracy: 0.9592\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 16s 172ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.1968 - val_accuracy: 0.9619\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 16s 174ms/step - loss: 0.0101 - accuracy: 0.9956 - val_loss: 0.2073 - val_accuracy: 0.9579\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 16s 179ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.1995 - val_accuracy: 0.9531\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 16s 177ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.2378 - val_accuracy: 0.9619\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 16s 174ms/step - loss: 0.0085 - accuracy: 0.9964 - val_loss: 0.2448 - val_accuracy: 0.9646\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 17s 182ms/step - loss: 0.0092 - accuracy: 0.9964 - val_loss: 0.2132 - val_accuracy: 0.9538\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 16s 176ms/step - loss: 0.0217 - accuracy: 0.9922 - val_loss: 0.2528 - val_accuracy: 0.9354\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 17s 187ms/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.1994 - val_accuracy: 0.9558\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 17s 185ms/step - loss: 0.0051 - accuracy: 0.9974 - val_loss: 0.1973 - val_accuracy: 0.9579\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 17s 181ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.2408 - val_accuracy: 0.9592\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 16s 177ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9592\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 17s 183ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9585\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 16s 177ms/step - loss: 7.6470e-04 - accuracy: 1.0000 - val_loss: 0.2478 - val_accuracy: 0.9619\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 16s 175ms/step - loss: 8.5138e-04 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9592\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 16s 174ms/step - loss: 7.4656e-04 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9572\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 16s 174ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.9619\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 18s 196ms/step - loss: 4.7286e-04 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9626\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 17s 185ms/step - loss: 4.3677e-04 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9626\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 17s 187ms/step - loss: 4.2736e-04 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9599\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 16s 177ms/step - loss: 3.3401e-04 - accuracy: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.9619\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 17s 183ms/step - loss: 3.0809e-04 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9619\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 16s 174ms/step - loss: 2.7223e-04 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9626\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 16s 177ms/step - loss: 2.5103e-04 - accuracy: 1.0000 - val_loss: 0.2709 - val_accuracy: 0.9592\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 17s 183ms/step - loss: 2.5119e-04 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9626\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 17s 180ms/step - loss: 2.3909e-04 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9633\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 16s 178ms/step - loss: 1.9618e-04 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9599\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 17s 188ms/step - loss: 1.9560e-04 - accuracy: 1.0000 - val_loss: 0.2894 - val_accuracy: 0.9626\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 17s 180ms/step - loss: 1.8106e-04 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.9626\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 17s 183ms/step - loss: 1.6930e-04 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.9626\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 16s 173ms/step - loss: 1.6001e-04 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9585\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 16s 173ms/step - loss: 1.6048e-04 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9626\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 16s 177ms/step - loss: 1.3521e-04 - accuracy: 1.0000 - val_loss: 0.2862 - val_accuracy: 0.9599\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 16s 172ms/step - loss: 2.2252e-04 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 0.9626\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 16s 173ms/step - loss: 1.1999e-04 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.9619\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 16s 176ms/step - loss: 1.0856e-04 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.9626\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 16s 175ms/step - loss: 1.0417e-04 - accuracy: 1.0000 - val_loss: 0.3095 - val_accuracy: 0.9626\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 16s 178ms/step - loss: 9.2681e-05 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.9626\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 17s 185ms/step - loss: 9.0593e-05 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.9619\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 18s 192ms/step - loss: 8.5662e-05 - accuracy: 1.0000 - val_loss: 0.3047 - val_accuracy: 0.9626\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 16s 177ms/step - loss: 8.8871e-05 - accuracy: 1.0000 - val_loss: 0.3116 - val_accuracy: 0.9633\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 16s 178ms/step - loss: 7.3121e-05 - accuracy: 1.0000 - val_loss: 0.3087 - val_accuracy: 0.9619\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 16s 178ms/step - loss: 6.9209e-05 - accuracy: 1.0000 - val_loss: 0.3200 - val_accuracy: 0.9633\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 16s 177ms/step - loss: 6.5562e-05 - accuracy: 1.0000 - val_loss: 0.3204 - val_accuracy: 0.9626\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 16s 175ms/step - loss: 5.7532e-05 - accuracy: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.9626\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 16s 178ms/step - loss: 5.5162e-05 - accuracy: 1.0000 - val_loss: 0.3286 - val_accuracy: 0.9626\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 16s 178ms/step - loss: 5.0875e-05 - accuracy: 1.0000 - val_loss: 0.3284 - val_accuracy: 0.9619\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 16s 174ms/step - loss: 8.7145e-05 - accuracy: 1.0000 - val_loss: 0.3262 - val_accuracy: 0.9613\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 17s 184ms/step - loss: 8.4336e-05 - accuracy: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.9619\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 17s 186ms/step - loss: 4.4382e-05 - accuracy: 1.0000 - val_loss: 0.3340 - val_accuracy: 0.9626\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 16s 175ms/step - loss: 5.0368e-05 - accuracy: 1.0000 - val_loss: 0.3383 - val_accuracy: 0.9619\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 16s 174ms/step - loss: 3.6466e-05 - accuracy: 1.0000 - val_loss: 0.3339 - val_accuracy: 0.9626\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 17s 183ms/step - loss: 3.4927e-05 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.9613\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 16s 174ms/step - loss: 3.1304e-05 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9633\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 16s 172ms/step - loss: 3.2927e-05 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9633\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 17s 180ms/step - loss: 3.3518e-05 - accuracy: 1.0000 - val_loss: 0.3622 - val_accuracy: 0.9626\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 16s 175ms/step - loss: 2.8063e-05 - accuracy: 1.0000 - val_loss: 0.3456 - val_accuracy: 0.9633\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 16s 173ms/step - loss: 2.3878e-05 - accuracy: 1.0000 - val_loss: 0.3378 - val_accuracy: 0.9599\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 16s 174ms/step - loss: 2.5852e-05 - accuracy: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.9633\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 16s 171ms/step - loss: 2.3095e-05 - accuracy: 1.0000 - val_loss: 0.3478 - val_accuracy: 0.9626\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 17s 186ms/step - loss: 2.3672e-05 - accuracy: 1.0000 - val_loss: 0.3496 - val_accuracy: 0.9613\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 17s 185ms/step - loss: 2.1862e-05 - accuracy: 1.0000 - val_loss: 0.3529 - val_accuracy: 0.9626\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 17s 182ms/step - loss: 2.8741e-05 - accuracy: 1.0000 - val_loss: 0.3694 - val_accuracy: 0.9606\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 16s 171ms/step - loss: 0.0749 - accuracy: 0.9787 - val_loss: 0.2221 - val_accuracy: 0.9463\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 16s 170ms/step - loss: 0.0118 - accuracy: 0.9952 - val_loss: 0.2205 - val_accuracy: 0.9531\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 16s 171ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.2315 - val_accuracy: 0.9565\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 16s 179ms/step - loss: 8.4110e-04 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9592\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 16s 174ms/step - loss: 6.1487e-04 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9565\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 16s 171ms/step - loss: 4.8981e-04 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9572\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 16s 172ms/step - loss: 4.3888e-04 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.9585\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 16s 171ms/step - loss: 4.0111e-04 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9592\n",
            "Generating adversarial examples for model 1...\n",
            "93/93 [==============================] - 1s 12ms/step - loss: 0.2848 - accuracy: 0.9576\n",
            "93/93 [==============================] - 1s 12ms/step - loss: 0.3180 - accuracy: 0.9549\n",
            "differnece 0.0027146339416503906\n",
            "Generating adversarial examples for model 2...\n",
            "93/93 [==============================] - 1s 8ms/step - loss: 0.2183 - accuracy: 0.9623\n",
            "93/93 [==============================] - 1s 8ms/step - loss: 0.2446 - accuracy: 0.9579\n",
            "differnece 0.004411280155181885\n",
            "Generating adversarial examples for model 3...\n",
            "93/93 [==============================] - 2s 22ms/step - loss: 0.3779 - accuracy: 0.9501\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.4123 - accuracy: 0.9454\n",
            "differnece 0.004750609397888184\n",
            "93/93 [==============================] - 2s 17ms/step\n",
            "93/93 [==============================] - 1s 10ms/step\n",
            "93/93 [==============================] - 3s 28ms/step\n",
            "Accuracy of ensemble model: 0.96\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, LSTM, Dense\n",
        "from keras.layers import Input, Dense, Dropout, Conv1D, MaxPooling1D, Flatten, LSTM, TimeDistributed\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "!pip install tensorflow\n",
        "from tensorflow import keras\n",
        "# Load UCI HAR dataset\n",
        "with zipfile.ZipFile(\"/content/gdrive/MyDrive/UCI HAR Dataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/tmp/har\")\n",
        "\n",
        "# Load the training and testing data\n",
        "X_train = np.loadtxt('/tmp/har/UCI HAR Dataset/train/X_train.txt')\n",
        "y_train = np.loadtxt('/tmp/har/UCI HAR Dataset/train/y_train.txt').astype(int)-1\n",
        "X_test = np.loadtxt('/tmp/har/UCI HAR Dataset/test/X_test.txt')\n",
        "y_test = np.loadtxt('/tmp/har/UCI HAR Dataset/test/y_test.txt').astype(int)-1\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Reshape data for Conv1\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Define model\n",
        "def create_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=100, activation='relu'))\n",
        "    model.add(Dense(units=num_classes, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "import numpy as np\n",
        "def random_time_shift(X, max_shift):\n",
        "    \"\"\"\n",
        "    Apply random time shift to the input data.\n",
        "    \"\"\"\n",
        "    if X.ndim == 2:\n",
        "        X = X[..., np.newaxis]\n",
        "    n_samples, n_timesteps, n_features = X.shape\n",
        "    new_X = np.zeros_like(X)\n",
        "    shifts = np.random.randint(-max_shift, max_shift, size=n_samples)\n",
        "    for i in range(n_samples):\n",
        "        new_X[i] = np.roll(X[i], shifts[i], axis=0)\n",
        "    return new_X\n",
        "\n",
        "\n",
        "# Create a list of models\n",
        "models = []\n",
        "for i in range(5):\n",
        "    model = create_model(input_shape=(X_train.shape[1], 1), num_classes=6)\n",
        "    models.append(model)\n",
        "\n",
        "# Train each model and evaluate its performance\n",
        "histories = []\n",
        "for i, model in enumerate(models):\n",
        "    print(f'Training model {i+1}')\n",
        "    X_train_shifted = random_time_shift(X_train, max_shift=10)\n",
        "    X_train_shifted = np.squeeze(X_train_shifted, axis=2)\n",
        "    X_train_shifted = X_train_shifted.reshape(X_train_shifted.shape[0], X_train_shifted.shape[1], 1)\n",
        "    history = model.fit(X_train_shifted, y_train, epochs=100, batch_size=64, validation_split=0.2)\n",
        "    loss, accuracy = model.evaluate(X_test, y_test)\n",
        "    print(f'Test accuracy of model {i+1}: {accuracy:.4f}')\n",
        "    histories.append(history)\n",
        "\n",
        "\n",
        "\n",
        "# Define function to create model with specified parameters\n",
        "def create_model(filters, kernel_size, units):\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=units, activation='relu'))\n",
        "    model.add(Dense(units=6, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Define parameters for each model in ensemble\n",
        "models_params = [\n",
        "    {'filters': 64, 'kernel_size': 3, 'units': 100},\n",
        "    {'filters': 32, 'kernel_size': 5, 'units': 50},\n",
        "    {'filters': 128, 'kernel_size': 2, 'units': 150}\n",
        "]\n",
        "def generate_adversarial(model, x, y, eps=0.001):\n",
        "    # Evaluate the original input and label to get the accuracy before adversarial perturbation\n",
        "    _, original_acc = model.evaluate(x, y)\n",
        "    \n",
        "    # Use the Fast Gradient Sign Method (FGSM) to generate adversarial example\n",
        "    loss_fn = keras.losses.CategoricalCrossentropy()\n",
        "    x_adv = []\n",
        "    for i in range(x.shape[0]):\n",
        "        image = tf.expand_dims(x[i], axis=0)\n",
        "        label = tf.expand_dims(y[i], axis=0)\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(image)\n",
        "            logits = model(image)\n",
        "            loss = loss_fn(label, logits)\n",
        "        gradients = tape.gradient(loss, image)\n",
        "        gradients_sign = tf.sign(gradients)\n",
        "        adv_image = image + eps * gradients_sign\n",
        "        adv_image = tf.clip_by_value(adv_image, -1, 1)\n",
        "        x_adv.append(adv_image.numpy()[0])\n",
        "    x_adv = np.array(x_adv)\n",
        "    \n",
        "    # Evaluate the adversarial example and original label to get the accuracy after adversarial perturbation\n",
        "    _, adv_acc = model.evaluate(x_adv, y)\n",
        "    \n",
        "    # Calculate the accuracy difference between the original and adversarial examples\n",
        "    acc_diff = original_acc - adv_acc\n",
        "    print(\"differnece\", acc_diff);\n",
        "    return x_adv\n",
        "\n",
        "# Create list of models with different parameters\n",
        "models = [create_model(**params) for params in models_params]\n",
        "import matplotlib.pyplot as plt\n",
        "# Train each model on the training data\n",
        "for i, model in enumerate(models):\n",
        "    print(f'Training model {i+1}...')\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2)\n",
        "\n",
        "for i, model in enumerate(models):\n",
        "   print(f'Generating adversarial examples for model {i+1}...')\n",
        "   x_adv = generate_adversarial(model, tf.convert_to_tensor(X_test), tf.convert_to_tensor(y_test))\n",
        "\n",
        "\n",
        "# Make predictions using each model on the test data\n",
        "y_preds = [model.predict(X_test) for model in models]\n",
        "\n",
        "# Combine predictions using majority voting\n",
        "y_pred_combined = np.argmax(np.sum(y_preds, axis=0), axis=1)\n",
        "\n",
        "# Compute accuracy of combined predictions\n",
        "accuracy = np.mean(y_pred_combined == np.argmax(y_test, axis=1))\n",
        "print(f'Accuracy of ensemble model: {accuracy:.2f}')\n",
        "\n",
        "# Plot the training and validation accuracy for all models\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i, history in enumerate(histories):\n",
        "    plt.plot(history.history['accuracy'], linestyle='-', marker='o', label=f'train {i+1}')\n",
        "    plt.plot(history.history['val_accuracy'], linestyle='--', marker='s', label=f'validation {i+1}')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ]
}